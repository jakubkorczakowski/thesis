@article{10.1145/3158674,
author = {Zhang, Dingwen and Fu, Huazhu and Han, Junwei and Borji, Ali and Li, Xuelong},
title = {A Review of Co-Saliency Detection Algorithms: Fundamentals, Applications, and Challenges},
year = {2018},
issue_date = {February 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3158674},
doi = {10.1145/3158674},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {Article 38},
numpages = {31},
keywords = {(Co-)saliency detection, image understanding, Computer vision}
}

@misc{cs231n,
 author = {Fei-Fei Li, Justin Johnson, Serena Young},
 editor = {{}},
 title = {CS231n: Convolutional Neural Networks for Visual Recognition},
 url = {http://cs231n.stanford.edu/2017/},
 lastchecked = {},
 originalyear = {11 sie 2017}
}

@inproceedings{iCoseg,
  title={icoseg: Interactive co-segmentation with intelligent scribble guidance},
  author={Batra, Dhruv and Kowdle, Adarsh and Parikh, Devi and Luo, Jiebo and Chen, Tsuhan},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={3169--3176},
  year={2010},
  organization={IEEE}
}

@misc{co-sal,
 author = {Huazhu Fu},
 editor = {{}},
 title = {Co-saliency Detection},
 url = {https://hzfu.github.io/proj_cosal_review.html},
 lastchecked = {},
 originalyear = {2020}
}

@article{MSRC,
  abstract = {This paper presents a new algorithm for the automatic recognition
	of object classes from images (categorization). Compact and yet discriminative
	appearance-based object class models are automatically learned from
	a set of training images. The method is simple and extremely fast,
	making it suitable for many applications such as semantic image retrieval,
	Web search, and interactive image editing. It classifies a region
	according to the proportions of different visual words (clusters
	in feature space). The specific visual words and the typical proportions
	in each object are learned from a segmented training set. The main
	contribution of this paper is twofold: i) an optimally compact visual
	dictionary is learned by pair-wise merging of visual words from an
	initially large dictionary. The final visual words are described
	by GMMs. ii) A novel statistical measure of discrimination is proposed
	which is optimized by each merge operation. High classification accuracy
	is demonstrated for nine object classes on photographs of real objects
	viewed under general lighting conditions, poses and viewpoints. The
	set of test images used for validation comprise: i) photographs acquired
	by us, ii) images from the Web and iii) images from the recently
	released Pascal dataset. The proposed algorithm performs well on
	both texture-rich objects (e.g. grass, sky, trees) and structure-rich
	ones (e.g. cars, bikes, planes).},
  added-at = {2009-09-12T19:19:34.000+0200},
  author = {Winn, J. and Criminisi, A. and Minka, T.},
  biburl = {https://www.bibsonomy.org/bibtex/2479e2efe3faefedadd0978bacdf8b3ec/mozaher},
  doi = {10.1109/ICCV.2005.171},
  file = {01544935.pdf:Winn2005.pdf:PDF},
  interhash = {a585b5dab8401171bc19736909e30368},
  intrahash = {479e2efe3faefedadd0978bacdf8b3ec},
  issn = {1550-5499},
  journal = {Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference
	on},
  keywords = {(artificial appearance-based categorization, class classification, dictionary, discriminative image intelligence), learning models, object recognition recognition, universal visual words},
  month = {17-21 Oct},
  owner = {Mozaher},
  pages = {1800-1807},
  timestamp = {2009-09-12T19:19:43.000+0200},
  title = {Object categorization by learned universal visual dictionary},
  volume = 2,
  year = 2005
}

@article{cosal2015,
author = {Zhang, Dingwen and Han, Junwei and Li, Chao and Wang, Jingdong and Li, Xuelong},
year = {2016},
month = {04},
pages = {},
title = {Detection of Co-salient Objects by Looking Deep and Wide},
volume = {120},
journal = {International Journal of Computer Vision},
doi = {10.1007/s11263-016-0907-4}
}


@article{ImagePair,
author = {Li, Hongliang and Ngan, King},
year = {2011},
month = {05},
pages = {3365-75},
title = {A Co-Saliency Model of Image Pairs},
volume = {20},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
doi = {10.1109/TIP.2011.2156803}
}

@InProceedings{Zhang_2019_CVPR,
author = {Zhang, Kaihua and Li, Tengpeng and Liu, Bo and Liu, Qingshan},
title = {Co-Saliency Detection via Mask-Guided Fully Convolutional Networks With Multi-Scale Label Smoothing},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@article{cifar,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@article{10.1109/TPAMI.2016.2572683,
author = {Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
title = {Fully Convolutional Networks for Semantic Segmentation},
year = {2017},
issue_date = {April 2017},
publisher = {IEEE Computer Society},
address = {USA},
volume = {39},
number = {4},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2016.2572683},
doi = {10.1109/TPAMI.2016.2572683},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = apr,
pages = {640–651},
numpages = {12}
}
  


@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
        }

@incollection{NIPS2012_4824,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@article{SimonyanZ14a,
  added-at = {2016-11-19T13:14:27.000+0100},
  author = {Simonyan, Karen and Zisserman, Andrew},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {https://www.bibsonomy.org/bibtex/20ee0434e0a70b329d5518f43f1742f7a/albinzehe},
  interhash = {4e6fa56cb7cf99400d5701543ee228de},
  intrahash = {0ee0434e0a70b329d5518f43f1742f7a},
  journal = {CoRR},
  keywords = {cnn ma-zehe neuralnet},
  timestamp = {2016-11-19T13:14:27.000+0100},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  url = {http://arxiv.org/abs/1409.1556},
  volume = {abs/1409.1556},
  year = 2014
}

@inproceedings{ChangLL11,
  added-at = {2014-07-31T00:00:00.000+0200},
  author = {Chang, Kai-Yueh and Liu, Tyng-Luh and Lai, Shang-Hong},
  biburl = {https://www.bibsonomy.org/bibtex/2541bd5a99b07c486c638b2eec7547960/dblp},
  booktitle = {CVPR},
  ee = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2011.5995415},
  interhash = {760b853ef6c1e750e6fcdc2f776838f5},
  intrahash = {541bd5a99b07c486c638b2eec7547960},
  isbn = {978-1-4577-0394-2},
  keywords = {dblp},
  pages = {2129-2136},
  publisher = {IEEE Computer Society},
  timestamp = {2015-06-19T15:57:58.000+0200},
  title = {From co-saliency to co-segmentation: An efficient and fully unsupervised energy minimization model.},
  url = {http://dblp.uni-trier.de/db/conf/cvpr/cvpr2011.html#ChangLL11},
  year = 2011
}

@article{midfeatex,
author = {Cao, Xiaochun and Tao, Zhiqiang and Zhang, Bao and Fu, Huazhu and Feng, Wei},
year = {2014},
month = {06},
pages = {4175-4186},
title = {Self-Adaptively Weighted Co-Saliency Detection via Rank Constraint},
volume = {23},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
doi = {10.1109/TIP.2014.2332399}
}

@article{highfeatex,
author = {Zhang, Dingwen and Han, Junwei and Han, Jungong and Shao, Ling},
year = {2015},
month = {11},
pages = {1-14},
title = {Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining},
volume = {27},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
doi = {10.1109/TNNLS.2015.2495161}
}

@article{bott,
author = {Fu, Huazhu and Cao, Xiaochun and Tu, Zhuowen},
year = {2013},
month = {04},
pages = {},
title = {Cluster-Based Co-Saliency Detection},
volume = {22},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
doi = {10.1109/TIP.2013.2260166}
}

@article{10.1109/TPAMI.2016.2567393,
author = {Zhang, Dingwen and Meng, Deyu and Han, Junwei},
title = {Co-Saliency Detection via a Self-Paced Multiple-Instance Learning Framework},
year = {2017},
issue_date = {May 2017},
publisher = {IEEE Computer Society},
address = {USA},
volume = {39},
number = {5},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2016.2567393},
doi = {10.1109/TPAMI.2016.2567393},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = may,
pages = {865–878},
numpages = {14}
}
  
